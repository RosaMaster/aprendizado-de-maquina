{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc27ba89",
   "metadata": {},
   "source": [
    "## Exercício de Apoio Semana 03\n",
    "\n",
    "Suponha que você tenha que implementar um modelo que identifique se é perigoso ou seguro (em termos de saúde alimentar) comer carne de 4 tipos de animais baseado nas características de cada um deles.\n",
    "\n",
    "##### Características:\n",
    "\n",
    "- Tamanho (pequeno ou grande)\n",
    "- Pele (lisa ou peluda)\n",
    "- Cor (marrom, verde ou vermelho)\n",
    "- Carne (macia ou dura)\n",
    "\n",
    "##### Considere a seguinte base de dados:\n",
    "\n",
    "| Pele   | Cor      | Tamanho | Carne | Classe   |\n",
    "| ------ | -------- | ------- | ----- | -------- |\n",
    "| peluda | marrom   | grande  | dura  | seguro   |\n",
    "| peluda | verde    | grande  | dura  | seguro   |\n",
    "| lisa   | vermelha | grande  | macia | perigoso |\n",
    "| peluda | verde    | grande  | macia | seguro   |\n",
    "| peluda | vermelha | pequeno | dura  | seguro   |\n",
    "| lisa   | vermelha | pequeno | dura  | seguro   |\n",
    "| lisa   | marrom   | pequeno | dura  | seguro   |\n",
    "| peluda | verde    | pequeno | macia | perigoso |\n",
    "| lisa   | verde    | pequeno | dura  | perigoso |\n",
    "| peluda | vermelha | grande  | dura  | seguro   |\n",
    "| lisa   | marrom   | grande  | macia | seguro   |\n",
    "| lisa   | verde    | pequeno | macia | perigoso |\n",
    "| peluda | vermelha | pequeno | macia | seguro   |\n",
    "| lisa   | vermelha | grande  | dura  | perigoso |\n",
    "| lisa   | vermelha | pequeno | dura  |          |\n",
    "| peluda | verde    | pequeno | dura  |          |\n",
    "\n",
    "##### Com essa base pré-classificada, podemos formular a seguinte questão:\n",
    "\n",
    "Dado um pequeno animal que tem pele lisa de cor vermelha e carne dura, é seguro comê-lo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba2441",
   "metadata": {},
   "source": [
    "## __RESPOSTA__\n",
    "\n",
    "##### Nosso animal pode ser representado por:\n",
    "\n",
    "x = [pequeno, lisa, vermelha, dura]\n",
    "\n",
    "##### E a pergunta, em forma de probabilidade condicional:\n",
    "\n",
    "P(y = seguro | x)\n",
    "\n",
    "##### Essa probabilidade deve ser lida como:\n",
    "\n",
    "- Qual a probabilidade de um animal ser seguro para comer dado que ele é:\n",
    "\n",
    "- pequeno, liso, vermelha, dura?\n",
    "\n",
    "- Pelo Teorema de Bayes, temos que:\n",
    "\n",
    "P(y = seguro / x) = ( P(x/y = seguro) . P(y = seguro) ) / P(x)\n",
    "\n",
    "- com P(x | y = seguro) sendo denominado likelihood ou verossimilhança, P(y = seguro) é a probabilidade a priori e P(x) o preditor.\n",
    "\n",
    "- Com essa fórmula e a tabela de exemplos, podemos calcular a probabilidade de cada animal não classificado pertencer a uma das duas classes.\n",
    "\n",
    "##### Expandindo, temos:\n",
    "\n",
    "P(y = seguro / x) = ∏i . P(xi / y = seguro) . P(y = seguro) / ∏i . P(xi)\n",
    "​\n",
    "Dado x = [pequeno, lisa, vermelha, dura]:\n",
    "\n",
    "- P(pequeno) =\n",
    "\n",
    "- P(lisa) =\n",
    "\n",
    "- P(vermelha) =\n",
    "\n",
    "- P(dura) =\n",
    "\n",
    "| Pele     | Cor          | Tamanho     | Carne     | Classe   |\n",
    "| -------- | ------------ | ----------- | --------- | -------- |\n",
    "| peluda   | marrom       | grande      | __dura__  | seguro   |\n",
    "| peluda   | verde        | grande      | __dura__  | seguro   |\n",
    "| __lisa__ | __vermelha__ | grande      | macia     | perigoso |\n",
    "| peluda   | verde        | grande      | macia     | seguro   |\n",
    "| peluda   | __vermelha__ | __pequeno__ | __dura__  | seguro   |\n",
    "| __lisa__ | __vermelha__ | __pequeno__ | __dura__  | seguro   |\n",
    "| __lisa__ | marrom       | __pequeno__ | __dura__  | seguro   |\n",
    "| peluda   | verde        | __pequeno__ | macia     | perigoso |\n",
    "| __lisa__ | verde        | __pequeno__ | __dura__  | perigoso |\n",
    "| peluda   | __vermelha__ | grande      | __dura__  | seguro   |\n",
    "| __lisa__ | marrom       | grande      | macia     | seguro   |\n",
    "| __lisa__ | verde        | __pequeno__ | macia     | perigoso |\n",
    "| peluda   | __vermelha__ | __pequeno__ | macia     | seguro   |\n",
    "| __lisa__ | __vermelha__ | grande      | __dura__  | perigoso |\n",
    "| __lisa__ | __vermelha__ | __pequeno__ | __dura__  |          |\n",
    "| peluda   | verde        | __pequeno__ | __dura__  |          |\n",
    "\n",
    "##### Dado x = [pequeno, lisa, vermelha, dura]:\n",
    "\n",
    "P(pequeno) = 7/14\n",
    "\n",
    "P(lisa) = 7/14\n",
    "\n",
    "P(vermelho) = 6/14\n",
    "\n",
    "P(dura) = 8/14\n",
    "\n",
    "P(x) = 2352/38416 = 0.06\n",
    "\n",
    "Em seguida:\n",
    "\n",
    "P(pequeno | y = seguro) = 4/9\n",
    "\n",
    "P(lisa | y = seguro) = 3/9\n",
    "\n",
    "P(vermelha | y = seguro) = 4/9\n",
    "\n",
    "P(dura | y = seguro) = 6/9\n",
    "\n",
    "P(x | y = seguro) = 288/6561 = 0.04\n",
    "\n",
    "##### E em seguida:\n",
    "\n",
    "P(pequeno | y = perigoso) = 3/5\n",
    "\n",
    "P(lisa | y = perigoso) = 4/5\n",
    "\n",
    "P(vermelha | y = perigoso) = 2/5\n",
    "\n",
    "P(dura | y = perigoso) = 2/5\n",
    "\n",
    "P(x | y = perigoso) = 48/625 = 0.08\n",
    "\n",
    "##### Com isso, podemos calcular:\n",
    "\n",
    "P(y = seguro | x) = 0.04 · 0.04 · 0.64/0.06 = 0.42\n",
    "\n",
    "P(y = perigoso | x) = 0.08 · 0.36/0.06 = 0.48\n",
    "\n",
    "Note que P(y = seguro | x) ≠ 1 − P(y = perigoso | x)\n",
    "\n",
    "Portanto, a probabilidade de comer o alimento ser perigoso é maior do que a probabilidade de não ser, então é melhor evitar comê-lo.\n",
    "\n",
    "##### Concluindo\n",
    "\n",
    "Existem alguns pontos nesse algoritmo a serem observados:\n",
    "\n",
    "- P(xi) é um denominador comum para todas as probabilidades, como queremos obter a maior probabilidade, podemos omitir.\n",
    "\n",
    "- Se um certo atributo categórico nunca apareceu na base de dados, sua probabilidade será 0 e teremos um resultado indefinido.\n",
    "\n",
    "- Se nosso vetor de atributos é muito grande, o termo P(xi | y = yi) tende a zero.\n",
    "\n",
    "Finalmente, para a maioria dos casos de classificação em que temos variáveis categóricas e conhecemos muitos exemplos pré-classificados, o Naive-Bayes tem uma resposta bastante próxima do esperado."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
