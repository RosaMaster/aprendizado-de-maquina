{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ebcd9c",
   "metadata": {},
   "source": [
    "Exercício de apoio - Semana 7: Comparando o desempenho de classificadores numa base de dados com faixas de preços de smartphones\n",
    "\n",
    "O objetivo deste exercício é fazer a comparação do desempenho usando três algoritmos de classificação: k-NN, SVM e Random Forest. Para isso, use o conjunto de dados sobre faixas de preço de smartphones, contendo várias características dos aparelhos (descritas abaixo). Verifique os valores obtidos para acurácia, precisão, revocação, medida F1. Use também a validação cruzada para verificar a acurácia dos classificadores.\n",
    "\n",
    "Mexa nos parâmetros dos algoritmos para conseguir os melhores resultados possíveis. Qual foi o desempenho obtido pelos classificadores? Alguns deles se destacou?\n",
    "\n",
    "O conjunto de dados contém os atributos descritos a seguir, e está disponível no link abaixo:\n",
    "\n",
    "https://raw.githubusercontent.com/higoramario/univesp-com410-aprendizado-de-maquinas/main/mobile-price.csv\n",
    "\n",
    "Classificação de preços de smartphones\n",
    "id: identificador\n",
    "battery_power: capacidade de armazenamento (mAh)\n",
    "blue: tem bluetooth (0 - não, 1 - sim)\n",
    "clock_speed: velocidade do processador (GHz)\n",
    "dual_sim: suporte a dois chips SIM (0 - não, 1 - sim)\n",
    "fc: câmera frontal (megapixels)\n",
    "four_g: suporte a 4G (0 - não, 1 - sim)\n",
    "int_memory: memória interna (GB)\n",
    "m_dep: profundidade (cm)\n",
    "mobile_wt: peso (g)\n",
    "n_cores: núcleos do processador\n",
    "pc: câmera principal (megapixels) \n",
    "px_height: altura de resolução (pixels)\n",
    "px_width: largura de resolução (pixels)\n",
    "ram: memória RAM (MB)\n",
    "sc_h: altura da tela (cm)\n",
    "sc_w: largura da tela (cm)\n",
    "talk_time: tempo de duração da bateria durante ligações (horas)\n",
    "three_g: suporte a 3G (0 - não, 1 - sim)\n",
    "touch_screen: tela sensível ao toque (0 - não, 1 - sim)\n",
    "wifi: suporte a wifi (0 - não, 1 - sim)\n",
    "Atributo classe:\n",
    "\n",
    "price_range: faixa de preço (0 - barato, 1 - médio, 2 - caro, 4 - muito caro)\n",
    "URL original do conjunto de dados\n",
    "https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification\n",
    "\n",
    "Fonte: Mobile Price Classification | Abhishek Sharma, Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72259e7",
   "metadata": {},
   "source": [
    "1. Importando as bibliotecas scikit-learn, pandas e matplotlib.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams['figure.figsize']=[15,10]\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    " \n",
    "\n",
    "2. Importe a base de dados direto da URL e verifique as primeiras linhas. O arquivo contém 2000 registros.\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/higoramario/univesp-com410-aprendizado-de-maquinas/main/mobile-price.csv'\n",
    "\n",
    "telefones = pd.read_csv(url, sep=',')\n",
    "\n",
    "telefones.head()\n",
    "\n",
    "telefones.info()\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    " RangeIndex: 2000 entries, 0 to 1999\n",
    " Data columns (total 21 columns):\n",
    "  #    Column         Non-Null Count  Dtype  \n",
    " ---  ------          --------------  -----  \n",
    "  0    battery_power  2000 non-null   int64   \n",
    "  1    blue           2000 non-null   int64   \n",
    "  2    clock_speed    2000 non-null   float64\n",
    "  3    dual_sim       2000 non-null   int64   \n",
    "  4    fc             2000 non-null   int64   \n",
    "  5    four_g         2000 non-null   int64   \n",
    "  6    int_memory     2000 non-null   int64   \n",
    "  7    m_dep          2000 non-null   float64\n",
    "  8    mobile_wt      2000 non-null   int64   \n",
    "  9    n_cores        2000 non-null   int64   \n",
    "  10   pc             2000 non-null   int64   \n",
    "  11   px_height      2000 non-null   int64   \n",
    "  12   px_width       2000 non-null   int64   \n",
    "  13   ram            2000 non-null   int64   \n",
    "  14   sc_h           2000 non-null   int64   \n",
    "  15   sc_w           2000 non-null   int64   \n",
    "  16   talk_time      2000 non-null   int64   \n",
    "  17   three_g        2000 non-null   int64   \n",
    "  18   touch_screen   2000 non-null   int64   \n",
    "  19   wifi           2000 non-null   int64   \n",
    "  20   price_range    2000 non-null   int64   \n",
    " dtypes: float64(2), int64(19)\n",
    " memory usage: 328.2 KB\n",
    "\n",
    " \n",
    "\n",
    "3. Separando os atributos dos rótulos e separando os dados de treinamento (80%) e teste (20%).\n",
    "\n",
    "atributos = telefones.iloc[:,:20]\n",
    "\n",
    "classes = telefones['price_range']\n",
    "\n",
    "telefones_treino, telefones_teste, classes_treino, classes_teste = train_test_split(atributos, classes, test_size = 0.2)\n",
    "\n",
    " \n",
    "\n",
    "4. Diminuindo a escala dos dados para melhorar o treinamento.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "telefones_treino = scaler.fit_transform(telefones_treino)\n",
    "\n",
    "telefones_teste = scaler.transform(telefones_teste)\n",
    "\n",
    " \n",
    "\n",
    "5. Classificando com o algoritmo k-NN.\n",
    "\n",
    "modelo_kNN = KNeighborsClassifier(n_neighbors = 80)\n",
    "\n",
    "modelo_kNN.fit(telefones_treino,classes_treino)\n",
    "\n",
    " \n",
    "\n",
    "6. Medindo a acurácia do classificador k-NN.\n",
    "\n",
    "predicao_kNN = modelo_kNN.predict(telefones_teste)\n",
    "\n",
    "acuracia_kNN = accuracy_score(classes_teste,predicao_kNN)\n",
    "\n",
    "print('Acurácia de classificação k-NN: {}'.format(round(acuracia_kNN,3)*100)+'%')\n",
    "\n",
    " \n",
    "\n",
    "Acurácia de classificação k-NN: 65.0%\n",
    "\n",
    " \n",
    "\n",
    "7. Medindo precisão, revogação e medida F1 do k-NN.\n",
    "\n",
    "print(classification_report(classes_teste, predicao_kNN))\n",
    "\n",
    " \n",
    "\n",
    "                    precision    recall   f1-score   support\n",
    " \n",
    "                   0        0.72      0.86        0.79            94\n",
    "                   1       0.55       0.46        0.50          104\n",
    "                   2       0.53       0.58        0.56          103\n",
    "                   3       0.81       0.72        0.76            99\n",
    " \n",
    "        accuracy                                   0.65          400\n",
    "      macro avg       0.65      0.66      0.65          400\n",
    " weighted avg       0.65       0.65       0.65          400\n",
    "\n",
    " \n",
    "\n",
    "8. Executando o k-NN com validação cruzada.\n",
    "\n",
    "cross_val_score(modelo_kNN, telefones_treino, classes_treino, cv=10)\n",
    "\n",
    "array([0.625  , 0.7     , 0.65625, 0.69375, 0.5375, 0.68125, 0.60625,\n",
    "        0.63125, 0.6375 , 0.6625 ])\n",
    "\n",
    " \n",
    "\n",
    "9. Classificando com SVM usando a função kernel polinomial.\n",
    "\n",
    "modelo_SVM = SVC(kernel = 'poly', degree = 2, gamma = 'scale', C = 2.0, coef0 = 25)\n",
    "\n",
    "modelo_SVM.fit(telefones_treino, classes_treino)\n",
    "\n",
    " \n",
    "\n",
    "10. Medindo a acurácia do classificador SVM.\n",
    "\n",
    "predicao_SVM = modelo_SVM.predict(telefones_teste)\n",
    "\n",
    "acuracia_SVM = accuracy_score(classes_teste,predicao_SVM)\n",
    "\n",
    "print('Acurácia de classificação SVM: {}'.format(round(acuracia_SVM,3)*100)+'%')\n",
    "\n",
    " \n",
    "\n",
    "Acurácia de classificação SVM: 95.199%\n",
    "\n",
    " \n",
    "\n",
    "11. Medindo precisão, revogação e medida F1 do SVM.\n",
    "\n",
    "print(classification_report(classes_teste, predicao_SVM))\n",
    "\n",
    "                     precision     recall  f1-score    support\n",
    " \n",
    "                    0        0.97      0.98         0.97            94\n",
    "                    1        0.95      0.93         0.94          104\n",
    "                    2        0.92      0.94         0.93          103\n",
    "                    3        0.97      0.96         0.96            99\n",
    " \n",
    "        accuracy                                    0.95          400\n",
    "      macro avg       0.95      0.95          0.95          400\n",
    " weighted avg       0.95       0.95         0.95          400\n",
    "\n",
    " \n",
    "\n",
    "12. Executando o SVM com validação cruzada.\n",
    "\n",
    "cross_val_score(modelo_SVM, telefones_treino, classes_treino, cv=10)\n",
    "\n",
    "array([0.95   , 0.95625, 0.95625, 0.95625, 0.93125, 0.94375, 0.975,\n",
    "        0.96875, 0.975, 0.96875])\n",
    "\n",
    " \n",
    "\n",
    "13. Classificando com Random Forest.\n",
    "\n",
    "modelo_RF = RandomForestClassifier()\n",
    "\n",
    "modelo_RF.fit(telefones_treino,classes_treino)\n",
    "\n",
    " \n",
    "\n",
    "14. Medindo a acurácia do classificador Random Forest.\n",
    "\n",
    "predicao_RF = modelo_RF.predict(telefones_teste)\n",
    "\n",
    "acuracia_RF = accuracy_score(classes_teste,predicao_RF)\n",
    "\n",
    "print('Acurácia de classificação RF: {}'.format(round(acuracia_RF,3)*100)+'%')\n",
    "\n",
    " \n",
    "\n",
    "Acurácia de classificação RF: 88.2%\n",
    "\n",
    " \n",
    "\n",
    "15. Medindo precisão, revogação e medida F1 do Random Forest.\n",
    "\n",
    "print(classification_report(classes_teste, predicao_RF))\n",
    "\n",
    "                     precision     recall   f1-score   support\n",
    " \n",
    "                    0        0.90      0.96         0.93            94\n",
    "                    1        0.86      0.81         0.83          104\n",
    "                    2        0.84      0.84         0.84          103\n",
    "                    3        0.94      0.93         0.93            99\n",
    " \n",
    "        accuracy                                    0.88          400\n",
    "     macro avg       0.88      0.88           0.88          400\n",
    " weighted avg       0.88       0.88         0.88          400\n",
    "\n",
    " \n",
    "\n",
    "16. Executando o Random Forest com validação cruzada.\n",
    "\n",
    "cross_val_score(modelo_RF, telefones_treino,classes_treino, cv=10)\n",
    "\n",
    "array([0.84375, 0.84375, 0.84375, 0.875  , 0.86875, 0.85625, 0.875  ,\n",
    "        0.86875, 0.8625 , 0.85   ])\n",
    "\n",
    " \n",
    "\n",
    "Concluindo\n",
    "\n",
    "Os resultados dos classificadores podem variar dependendo dos parâmetros que foram selecionados. Neste caderno, SVM teve um desempenho melhor para esses dados, com Random Forest apresentando um desempenho próximo. Já k-NN não funcionou bem com os parâmetros de treinamento que foram usados.\n",
    "\n",
    "Experimente ver os resultados alterando os parâmetros dos algoritmos para ver se consegue melhores resultados. Se quiser, aplique o conjunto de dados a outros algoritmos de classificação.\n",
    "\n",
    " \n",
    "\n",
    "Acesse o gabarito do código em Python no link a seguir:\n",
    "\n",
    "com410-semana-7-exercicio-apoio-comparacao-gabarito.ipynb\n",
    "\n",
    " \n",
    "\n",
    "Versões das bibliotecas\n",
    "\n",
    "Esse tutorial está usando as seguintes versões de bibliotecas:\n",
    "\n",
    "matplotlib==3.2.2\n",
    "\n",
    "pandas==1.3.5\n",
    "\n",
    "scikit-learn==1.0.2\n",
    "\n",
    "Python==3.7"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
